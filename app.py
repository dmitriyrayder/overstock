import streamlit as st
import pandas as pd
import numpy as np
from prophet import Prophet
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
import warnings
warnings.filterwarnings('ignore')

st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ —Ç–æ–≤–∞—Ä–æ–≤", layout="wide")

if 'run_analysis' not in st.session_state:
    st.session_state.run_analysis = False

st.title("üîç –ê–Ω–∞–ª–∏–∑ —Ç–æ–≤–∞—Ä–æ–≤: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ —Å–Ω—è—Ç–∏–µ")

# === –°–ê–ô–î–ë–ê–† ===
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    TOP_N = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø-–∞—Ä—Ç–∏–∫—É–ª–æ–≤ –¥–ª—è Prophet", 10, 100, 50)
    
    st.subheader("üéØ –ö—Ä–∏—Ç–µ—Ä–∏–∏ —Å–Ω—è—Ç–∏—è")
    zero_weeks_threshold = st.slider("–ù–µ–¥–µ–ª—å –ø–æ–¥—Ä—è–¥ –±–µ–∑ –ø—Ä–æ–¥–∞–∂", 8, 20, 12)
    min_total_sales = st.slider("–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ–±—ä–µ–º –ø—Ä–æ–¥–∞–∂", 1, 50, 5)
    max_store_ratio = st.slider("–ú–∞–∫—Å. –¥–æ–ª—è –º–∞–≥–∞–∑–∏–Ω–æ–≤ –±–µ–∑ –ø—Ä–æ–¥–∞–∂", 0.7, 0.95, 0.85, 0.05)
    
    st.subheader("ü§ñ –ú–æ–¥–µ–ª—å ML")
    use_balanced_model = st.checkbox("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫—É –∫–ª–∞—Å—Å–æ–≤", value=True)
    final_threshold = st.slider("–§–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è —Å–Ω—è—Ç–∏—è", 0.5, 0.9, 0.7, 0.05)

# === –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ===
st.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ Excel —Ñ–∞–π–ª", type=['xlsx', 'xls'])

df = None
data_loaded = False

if uploaded_file is not None:
    try:
        excel_file = pd.ExcelFile(uploaded_file)
        sheet_names = excel_file.sheet_names
        
        if len(sheet_names) > 1:
            selected_sheet = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –ª–∏—Å—Ç Excel:", sheet_names)
        else:
            selected_sheet = sheet_names[0]
        
        df = pd.read_excel(uploaded_file, sheet_name=selected_sheet)
        st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –∏–∑ –ª–∏—Å—Ç–∞ '{selected_sheet}'")
        
        st.subheader("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö")
        available_cols = list(df.columns)
        st.write(f"**–ù–∞–π–¥–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏:** {', '.join(available_cols)}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏:**")
            date_col = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Å –¥–∞—Ç–æ–π:", available_cols, 
                                  index=next((i for i, col in enumerate(available_cols) 
                                           if any(word in col.lower() for word in ['–¥–∞—Ç', 'date'])), 0))
            art_col = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Å –∞—Ä—Ç–∏–∫—É–ª–æ–º:", available_cols,
                                 index=next((i for i, col in enumerate(available_cols) 
                                          if any(word in col.lower() for word in ['–∞—Ä—Ç', 'art'])), 0))
            qty_col = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º:", available_cols,
                                 index=next((i for i, col in enumerate(available_cols) 
                                          if any(word in col.lower() for word in ['–∫–æ–ª', 'qty', '–∫–æ–ª–∏—á–µ—Å—Ç–≤'])), 0))
        
        with col2:
            st.write("**–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏:**")
            magazin_col = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Å –º–∞–≥–∞–∑–∏–Ω–æ–º:", available_cols,
                                     index=next((i for i, col in enumerate(available_cols) 
                                              if any(word in col.lower() for word in ['–º–∞–≥', 'magazin', '–º–∞–≥–∞–∑–∏–Ω'])), 0))
            name_col = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º:", available_cols,
                                  index=next((i for i, col in enumerate(available_cols) 
                                           if any(word in col.lower() for word in ['–Ω–∞–∑–≤', 'name', '–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω'])), 0))
            
            # –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–∫–∏ —Å —Å–µ–≥–º–µ–Ω—Ç–æ–º
            segment_col = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Å —Å–µ–≥–º–µ–Ω—Ç–æ–º (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):", 
                                     ['–ë–µ–∑ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏'] + available_cols)
        
        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏
        column_mapping = {
            date_col: 'Data',
            art_col: 'Art', 
            qty_col: 'Qty',
            magazin_col: 'Magazin',
            name_col: 'Name'
        }
        
        if segment_col != '–ë–µ–∑ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏':
            column_mapping[segment_col] = 'Segment'
        
        df = df.rename(columns=column_mapping)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        required_cols = ['Data', 'Art', 'Qty', 'Magazin', 'Name']
        missing_cols = [col for col in required_cols if col not in df.columns]
        
        if missing_cols:
            st.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")
        else:
            st.success("‚úÖ –í—Å–µ –∫–æ–ª–æ–Ω–∫–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω—ã")
            
            # –í—ã–±–æ—Ä —Å–µ–≥–º–µ–Ω—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            if 'Segment' in df.columns:
                st.subheader("üéØ –í—ã–±–æ—Ä —Å–µ–≥–º–µ–Ω—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
                unique_segments = sorted(df['Segment'].dropna().unique())
                
                col1, col2 = st.columns(2)
                with col1:
                    selected_segment = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Å–µ–≥–º–µ–Ω—Ç:", 
                                                  ['–í—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã'] + list(unique_segments))
                with col2:
                    if selected_segment != '–í—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã':
                        segment_count = len(df[df['Segment'] == selected_segment])
                        segment_arts = df[df['Segment'] == selected_segment]['Art'].nunique()
                        st.info(f"üìä –ó–∞–ø–∏—Å–µ–π: {segment_count}, –ê—Ä—Ç–∏–∫—É–ª–æ–≤: {segment_arts}")
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É —Å–µ–≥–º–µ–Ω—Ç—É
                if selected_segment != '–í—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã':
                    df = df[df['Segment'] == selected_segment].copy()
                    st.success(f"‚úÖ –í—ã–±—Ä–∞–Ω —Å–µ–≥–º–µ–Ω—Ç: {selected_segment}")
            
            data_loaded = True
            
            with st.expander("üìä –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö"):
                st.dataframe(df.head())
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π", len(df))
                with col2:
                    st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞—Ä—Ç–∏–∫—É–ª–æ–≤", df['Art'].nunique())
                with col3:
                    date_range_min = pd.to_datetime(df['Data'], errors='coerce').min()
                    date_range_max = pd.to_datetime(df['Data'], errors='coerce').max()
                    if pd.notna(date_range_min) and pd.notna(date_range_max):
                        st.metric("–ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö", f"{date_range_min.strftime('%Y-%m-%d')} - {date_range_max.strftime('%Y-%m-%d')}")
                    else:
                        st.metric("–ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö", "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç")
            
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}")
        st.stop()
else:
    st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")

if data_loaded:
    st.header("üöÄ –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞")
    if st.button("‚ñ∂Ô∏è –ù–ê–ß–ê–¢–¨ –ê–ù–ê–õ–ò–ó", type="primary", use_container_width=True):
        st.session_state.run_analysis = True
    
    if not st.session_state.get('run_analysis', False):
        st.info("üëÜ –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞")
        st.stop()
else:
    st.stop()

# === –û–ë–†–ê–ë–û–¢–ö–ê ===
with st.spinner("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
    df['Data'] = pd.to_datetime(df['Data'], dayfirst=True, errors='coerce')
    df = df.dropna(subset=['Data'])
    df = df[df['Qty'] >= 0]
    df['year_week'] = df['Data'].dt.strftime('%Y-%U')
    
    # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –Ω–µ–¥–µ–ª—è–º
    weekly = df.groupby(['Art', 'year_week'])[['Qty']].sum().reset_index()
    unique_weeks = sorted(df['year_week'].unique())
    all_arts = df['Art'].unique()
    all_weeks = pd.MultiIndex.from_product([all_arts, unique_weeks], names=['Art', 'year_week'])
    weekly = weekly.set_index(['Art', 'year_week']).reindex(all_weeks, fill_value=0).reset_index()
    
    # ABC-–∞–Ω–∞–ª–∏–∑ —Ç–æ–≤–∞—Ä–æ–≤
    abc_analysis = df.groupby('Art').agg({
        'Qty': ['sum', 'mean', 'count'],
        'Data': ['min', 'max']
    }).reset_index()
    
    abc_analysis.columns = ['Art', 'total_qty', 'avg_qty', 'sales_count', 'first_sale', 'last_sale']
    abc_analysis['days_in_catalog'] = (abc_analysis['last_sale'] - abc_analysis['first_sale']).dt.days + 1
    abc_analysis['sales_velocity'] = abc_analysis['total_qty'] / np.maximum(abc_analysis['days_in_catalog'], 1)
    
    abc_analysis = abc_analysis.sort_values('total_qty', ascending=False)
    abc_analysis['cum_qty'] = abc_analysis['total_qty'].cumsum()
    abc_analysis['cum_qty_pct'] = abc_analysis['cum_qty'] / abc_analysis['total_qty'].sum()
    
    def get_abc_category(cum_pct):
        if cum_pct <= 0.8:
            return 'A'
        elif cum_pct <= 0.95:
            return 'B'
        else:
            return 'C'
    
    abc_analysis['abc_category'] = abc_analysis['cum_qty_pct'].apply(get_abc_category)
    
    # –†–∞—Å—á–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã—Ö —Ñ–∏—á–µ–π
    def compute_enhanced_features(group):
        sorted_group = group.sort_values('year_week')
        qty_series = sorted_group['Qty']
        
        ma_3 = qty_series.rolling(3, min_periods=1).mean().iloc[-1]
        ma_6 = qty_series.rolling(6, min_periods=1).mean().iloc[-1]
        ma_12 = qty_series.rolling(12, min_periods=1).mean().iloc[-1]
        
        consecutive_zeros = 0
        for val in reversed(qty_series.values):
            if val == 0:
                consecutive_zeros += 1
            else:
                break
        
        zero_weeks_12 = (qty_series.tail(12) == 0).sum()
        
        if len(qty_series) >= 4:
            x = np.arange(len(qty_series))
            trend = np.polyfit(x, qty_series, 1)[0]
        else:
            trend = 0
        
        volatility = qty_series.std() if len(qty_series) > 1 else 0
        
        return pd.DataFrame({
            'ma_3': [ma_3], 'ma_6': [ma_6], 'ma_12': [ma_12],
            'consecutive_zeros': [consecutive_zeros], 'zero_weeks_12': [zero_weeks_12],
            'trend': [trend], 'volatility': [volatility]
        })
    
    features = weekly.groupby('Art').apply(compute_enhanced_features, include_groups=False).reset_index()
    features = features.drop('level_1', axis=1, errors='ignore')
    
    # –î–æ–ª—è –º–∞–≥–∞–∑–∏–Ω–æ–≤ –±–µ–∑ –ø—Ä–æ–¥–∞–∂
    df['has_sales'] = df['Qty'] > 0
    store_sales = df.groupby(['Art', 'Magazin'])['has_sales'].max().reset_index()
    store_ratio = store_sales.groupby('Art')['has_sales'].mean().reset_index()
    store_ratio['no_store_ratio'] = 1 - store_ratio['has_sales']
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å ABC-–∞–Ω–∞–ª–∏–∑–æ–º
    features = features.merge(abc_analysis[['Art', 'total_qty', 'sales_velocity', 'abc_category', 'days_in_catalog']], on='Art', how='left')
    features = features.merge(store_ratio[['Art', 'no_store_ratio']], on='Art', how='left')
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –±–æ–ª–µ–µ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ª–µ–π–±–ª–æ–≤ –ø–æ —Å–µ–≥–º–µ–Ω—Ç—É
    def create_balanced_labels(row):
        score = 0
        
        if row['abc_category'] == 'C':
            if row['consecutive_zeros'] >= zero_weeks_threshold:
                score += 3
            elif row['zero_weeks_12'] >= zero_weeks_threshold//2:
                score += 2
            if row['no_store_ratio'] > max_store_ratio:
                score += 2
            if row['total_qty'] < min_total_sales:
                score += 2
            if row['trend'] < -0.1:
                score += 1
        elif row['abc_category'] in ['A', 'B']:
            if row['consecutive_zeros'] >= zero_weeks_threshold * 1.5:
                score += 2
            if row['no_store_ratio'] > 0.95:
                score += 1
        
        return 1 if score >= 4 else 0
    
    features['label'] = features.apply(create_balanced_labels, axis=1)
    
    # –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π —á–µ—Ä–µ–∑ class_weight
    feature_cols = ['ma_3', 'ma_6', 'ma_12', 'consecutive_zeros', 'zero_weeks_12', 
                   'trend', 'volatility', 'no_store_ratio', 'total_qty', 'sales_velocity']
    
    X = features[feature_cols].fillna(0)
    y = features['label']
    
    st.write(f"**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Å–µ–≥–º–µ–Ω—Ç–µ:** –°–Ω—è—Ç—å: {y.sum()}, –û—Å—Ç–∞–≤–∏—Ç—å: {len(y) - y.sum()}")
    
    if len(y.unique()) > 1 and y.sum() > 0:
        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42, test_size=0.3)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ class_weight –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
        if use_balanced_model:
            clf = RandomForestClassifier(
                n_estimators=100, 
                random_state=42, 
                class_weight='balanced',  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞
                max_depth=10,
                min_samples_split=5, 
                min_samples_leaf=2
            )
        else:
            clf = RandomForestClassifier(
                n_estimators=100, 
                random_state=42,
                max_depth=10,
                min_samples_split=5, 
                min_samples_leaf=2
            )
        
        clf.fit(X_train, y_train)
        features['prob_dying'] = clf.predict_proba(X)[:, 1]
        train_score = clf.score(X_train, y_train)
        test_score = clf.score(X_test, y_test)
        
    else:
        st.warning("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
        features['prob_dying'] = features['label'].astype(float)
        train_score = test_score = 0.0

# === PROPHET –ü–†–û–ì–ù–û–ó–´ ===
with st.spinner("üìà –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ Prophet..."):
    qty_by_art = features.sort_values('total_qty', ascending=False).head(TOP_N)['Art']
    forecast_dfs = []
    
    progress_bar = st.progress(0)
    for i, art in enumerate(qty_by_art):
        sales = df[df['Art'] == art].groupby('Data')[['Qty']].sum().reset_index()
        if len(sales) < 8:
            continue
        
        sales.columns = ['ds', 'y']
        try:
            model = Prophet(daily_seasonality=False, weekly_seasonality=True, 
                          yearly_seasonality=True, changepoint_prior_scale=0.1)
            model.fit(sales)
            future = model.make_future_dataframe(periods=30)
            forecast = model.predict(future)
            median_30 = forecast.tail(30)['yhat'].median()
            forecast_dfs.append({'Art': art, 'forecast_30_median': max(0, median_30)})
        except:
            continue
        
        progress_bar.progress((i + 1) / len(qty_by_art))
    
    forecast_df = pd.DataFrame(forecast_dfs)

# === –§–ò–ù–ê–õ–¨–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê ===
final = features.merge(forecast_df, on='Art', how='left')
final = final.merge(df[['Art', 'Name']].drop_duplicates(), on='Art', how='left')

# –ü—Ä–∞–≤–∏–ª–∞ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
def get_detailed_reason(row):
    reasons = []
    if row['abc_category'] == 'C':
        reasons.append(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è C")
    if row['consecutive_zeros'] >= zero_weeks_threshold:
        reasons.append(f"–ë–µ–∑ –ø—Ä–æ–¥–∞–∂ {int(row['consecutive_zeros'])} –Ω–µ–¥–µ–ª—å")
    if row['zero_weeks_12'] >= zero_weeks_threshold//2:
        reasons.append(f"–ò–∑ 12 –Ω–µ–¥–µ–ª—å {int(row['zero_weeks_12'])} –±–µ–∑ –ø—Ä–æ–¥–∞–∂")
    if row['no_store_ratio'] > max_store_ratio:
        reasons.append(f"–í {(1-row['no_store_ratio'])*100:.0f}% –º–∞–≥–∞–∑–∏–Ω–æ–≤")
    if row['total_qty'] < min_total_sales:
        reasons.append(f"–ú–∞–ª—ã–π –æ–±—ä–µ–º ({row['total_qty']:.1f})")
    if pd.notnull(row['forecast_30_median']) and row['forecast_30_median'] < 0.5:
        reasons.append("–ü—Ä–æ–≥–Ω–æ–∑ –±–ª–∏–∑–æ–∫ –∫ –Ω—É–ª—é")
    if row['trend'] < -0.1:
        reasons.append("–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π —Ç—Ä–µ–Ω–¥")
    return "; ".join(reasons) if reasons else "–°—Ç–∞–±–∏–ª—å–Ω—ã–µ –ø—Ä–æ–¥–∞–∂–∏"

def get_final_recommendation(row):
    ml_score = row['prob_dying']
    if (row['abc_category'] == 'C' and row['consecutive_zeros'] >= zero_weeks_threshold and 
        row['total_qty'] < min_total_sales):
        return "üö´ –°–Ω—è—Ç—å"
    if ml_score > final_threshold:
        return "üö´ –°–Ω—è—Ç—å"
    elif ml_score > final_threshold * 0.7:
        return "‚ö†Ô∏è –ù–∞–±–ª—é–¥–∞—Ç—å"
    else:
        return "‚úÖ –û—Å—Ç–∞–≤–∏—Ç—å"

final['–ü—Ä–∏—á–∏–Ω–∞'] = final.apply(get_detailed_reason, axis=1)
final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è'] = final.apply(get_final_recommendation, axis=1)

# === –†–ï–ó–£–õ–¨–¢–ê–¢–´ ===
st.header("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")

col1, col2, col3, col4 = st.columns(4)
with col1:
    total_products = len(final)
    st.metric("–í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤", total_products)
with col2:
    candidates_remove = len(final[final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è'] == "üö´ –°–Ω—è—Ç—å"])
    st.metric("–ö —Å–Ω—è—Ç–∏—é", candidates_remove, f"{candidates_remove/total_products*100:.1f}%")
with col3:
    candidates_watch = len(final[final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è'] == "‚ö†Ô∏è –ù–∞–±–ª—é–¥–∞—Ç—å"])
    st.metric("–ù–∞–±–ª—é–¥–∞—Ç—å", candidates_watch, f"{candidates_watch/total_products*100:.1f}%")
with col4:
    if 'test_score' in locals() and test_score > 0:
        st.metric("–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏", f"{test_score:.2f}")

# ABC —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
st.subheader("üìà ABC –∞–Ω–∞–ª–∏–∑")
abc_dist = final['abc_category'].value_counts()
col1, col2, col3 = st.columns(3)
with col1:
    st.metric("–ö–∞—Ç–µ–≥–æ—Ä–∏—è A", abc_dist.get('A', 0))
with col2:
    st.metric("–ö–∞—Ç–µ–≥–æ—Ä–∏—è B", abc_dist.get('B', 0))
with col3:
    st.metric("–ö–∞—Ç–µ–≥–æ—Ä–∏—è C", abc_dist.get('C', 0))

# === –§–ò–õ–¨–¢–†–´ ===
st.subheader("üîç –§–∏–ª—å—Ç—Ä—ã")
col1, col2, col3 = st.columns(3)

with col1:
    filter_recommendation = st.selectbox("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:", 
                                       ["–í—Å–µ", "üö´ –°–Ω—è—Ç—å", "‚ö†Ô∏è –ù–∞–±–ª—é–¥–∞—Ç—å", "‚úÖ –û—Å—Ç–∞–≤–∏—Ç—å"])
    filter_abc = st.selectbox("ABC –∫–∞—Ç–µ–≥–æ—Ä–∏—è:", ["–í—Å–µ", "A", "B", "C"])

with col2:
    min_prob = st.slider("–ú–∏–Ω. –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–Ω—è—Ç–∏—è", 0.0, 1.0, 0.0, 0.1)
    min_zero_weeks = st.slider("–ú–∏–Ω. –Ω–µ–¥–µ–ª—å –±–µ–∑ –ø—Ä–æ–¥–∞–∂", 0, 20, 0)

with col3:
    search_art = st.text_input("–ü–æ–∏—Å–∫ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É/–Ω–∞–∑–≤–∞–Ω–∏—é")

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
filtered_df = final.copy()

if filter_recommendation != "–í—Å–µ":
    filtered_df = filtered_df[filtered_df['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è'] == filter_recommendation]

if filter_abc != "–í—Å–µ":
    filtered_df = filtered_df[filtered_df['abc_category'] == filter_abc]

filtered_df = filtered_df[
    (filtered_df['prob_dying'] >= min_prob) &
    (filtered_df['consecutive_zeros'] >= min_zero_weeks)
]

if search_art:
    mask = (filtered_df['Art'].astype(str).str.contains(search_art, case=False, na=False) |
            filtered_df['Name'].astype(str).str.contains(search_art, case=False, na=False))
    filtered_df = filtered_df[mask]

# === –¢–ê–ë–õ–ò–¶–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ===
st.subheader(f"üìã –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ({len(filtered_df)} —Ç–æ–≤–∞—Ä–æ–≤)")

display_df = filtered_df[['Art', 'Name', 'abc_category', 'total_qty', 'consecutive_zeros', 
                         'no_store_ratio', 'forecast_30_median', 'prob_dying', 
                         '–ü—Ä–∏—á–∏–Ω–∞', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è']].copy()

display_df['no_store_ratio'] = display_df['no_store_ratio'].round(2)
display_df['forecast_30_median'] = display_df['forecast_30_median'].round(1)
display_df['prob_dying'] = display_df['prob_dying'].round(3)
display_df['total_qty'] = display_df['total_qty'].round(1)

display_df.columns = ['–ê—Ä—Ç–∏–∫—É–ª', '–ù–∞–∑–≤–∞–Ω–∏–µ', 'ABC', '–û–±—â–∏–π_–æ–±—ä–µ–º', '–ù–µ–¥–µ–ª—å_–±–µ–∑_–ø—Ä–æ–¥–∞–∂', 
                     '–î–æ–ª—è_–º–∞–≥_–±–µ–∑_–ø—Ä–æ–¥–∞–∂', '–ü—Ä–æ–≥–Ω–æ–∑_30–¥–Ω', '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_—Å–Ω—è—Ç–∏—è', '–ü—Ä–∏—á–∏–Ω–∞', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è']

st.dataframe(display_df, use_container_width=True)

# === –≠–ö–°–ü–û–†–¢ ===
st.subheader("üíæ –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

if st.button("üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ Excel"):
    output = final[['Art', 'Name', 'abc_category', 'total_qty', 'consecutive_zeros', 
                   'no_store_ratio', 'forecast_30_median', 'prob_dying', '–ü—Ä–∏—á–∏–Ω–∞', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è']].copy()
    
    from io import BytesIO
    buffer = BytesIO()
    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
        output.to_excel(writer, sheet_name='–†–µ–∑—É–ª—å—Ç–∞—Ç—ã', index=False)
        
        stats = pd.DataFrame({
            '–ú–µ—Ç—Ä–∏–∫–∞': ['–í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤', '–ö —Å–Ω—è—Ç–∏—é', '–ù–∞–±–ª—é–¥–∞—Ç—å', '–û—Å—Ç–∞–≤–∏—Ç—å', '–ü–æ—Ä–æ–≥ ML'],
            '–ó–Ω–∞—á–µ–Ω–∏–µ': [total_products, candidates_remove, candidates_watch, 
                        total_products - candidates_remove - candidates_watch, final_threshold]
        })
        stats.to_excel(writer, sheet_name='–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', index=False)
        
        abc_summary = final.groupby(['abc_category', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è']).size().unstack(fill_value=0)
        abc_summary.to_excel(writer, sheet_name='ABC_–∞–Ω–∞–ª–∏–∑')
    
    st.download_button(
        label="üì• –°–∫–∞—á–∞—Ç—å Excel",
        data=buffer.getvalue(),
        file_name="product_analysis_by_segment.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )