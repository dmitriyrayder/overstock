import streamlit as st
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# –£—Å–ª–æ–≤–Ω—ã–π –∏–º–ø–æ—Ä—Ç Prophet
try:
    from prophet import Prophet
    PROPHET_AVAILABLE = True
except ImportError:
    PROPHET_AVAILABLE = False
    st.warning("‚ö†Ô∏è Prophet –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü—Ä–æ–≥–Ω–æ–∑—ã –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight

st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ —Ç–æ–≤–∞—Ä–æ–≤", layout="wide")

if 'run_analysis' not in st.session_state:
    st.session_state.run_analysis = False

st.title("üîç –ê–Ω–∞–ª–∏–∑ —Ç–æ–≤–∞—Ä–æ–≤: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ —Å–Ω—è—Ç–∏–µ")

# === –°–ê–ô–î–ë–ê–† ===
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    TOP_N = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø-–∞—Ä—Ç–∏–∫—É–ª–æ–≤ –¥–ª—è Prophet", 10, 100, 50)
    
    st.subheader("üéØ –ö—Ä–∏—Ç–µ—Ä–∏–∏ —Å–Ω—è—Ç–∏—è")
    zero_weeks_threshold = st.slider("–ù–µ–¥–µ–ª—å –ø–æ–¥—Ä—è–¥ –±–µ–∑ –ø—Ä–æ–¥–∞–∂", 8, 20, 12)
    min_total_sales = st.slider("–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ–±—ä–µ–º –ø—Ä–æ–¥–∞–∂", 1, 50, 5)
    max_store_ratio = st.slider("–ú–∞–∫—Å. –¥–æ–ª—è –º–∞–≥–∞–∑–∏–Ω–æ–≤ –±–µ–∑ –ø—Ä–æ–¥–∞–∂", 0.7, 0.95, 0.85, 0.05)
    
    st.subheader("ü§ñ –ú–æ–¥–µ–ª—å ML")
    use_balanced_model = st.checkbox("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫—É –∫–ª–∞—Å—Å–æ–≤", value=True)
    final_threshold = st.slider("–§–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è —Å–Ω—è—Ç–∏—è", 0.5, 0.9, 0.7, 0.05)

# === –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ===
st.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")

# –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—á–∞–Ω–∏–µ –æ —Ñ–æ—Ä–º–∞—Ç–µ —Ñ–∞–π–ª–∞
st.info("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–∞—à Excel —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–ª–æ–Ω–∫–∏: –¥–∞—Ç–∞, –∞—Ä—Ç–∏–∫—É–ª, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, –º–∞–≥–∞–∑–∏–Ω, –Ω–∞–∑–≤–∞–Ω–∏–µ")

uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ Excel —Ñ–∞–π–ª", type=['xlsx', 'xls'])

df = None
data_loaded = False

if uploaded_file is not None:
    try:
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        file_size = len(uploaded_file.read())
        uploaded_file.seek(0)  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —É–∫–∞–∑–∞—Ç–µ–ª—å –≤ –Ω–∞—á–∞–ª–æ
        
        if file_size > 50 * 1024 * 1024:  # 50MB –ª–∏–º–∏—Ç
            st.error("‚ùå –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 50MB")
            st.stop()
        
        excel_file = pd.ExcelFile(uploaded_file)
        sheet_names = excel_file.sheet_names
        
        if len(sheet_names) > 1:
            selected_sheet = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –ª–∏—Å—Ç Excel:", sheet_names)
        else:
            selected_sheet = sheet_names[0]
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è —á—Ç–µ–Ω–∏—è
        df = pd.read_excel(uploaded_file, sheet_name=selected_sheet, nrows=100000)
        
        if len(df) == 100000:
            st.warning("‚ö†Ô∏è –§–∞–π–ª –æ–±—Ä–µ–∑–∞–Ω –¥–æ 100,000 —Å—Ç—Ä–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –∏–∑ –ª–∏—Å—Ç–∞ '{selected_sheet}'")
        
        st.subheader("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö")
        available_cols = list(df.columns)
        st.write(f"**–ù–∞–π–¥–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏:** {', '.join(available_cols[:10])}{'...' if len(available_cols) > 10 else ''}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏:**")
            date_col = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Å –¥–∞—Ç–æ–π:", available_cols, 
                                  index=next((i for i, col in enumerate(available_cols) 
                                           if any(word in col.lower() for word in ['–¥–∞—Ç', 'date'])), 0))
            art_col = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Å –∞—Ä—Ç–∏–∫—É–ª–æ–º:", available_cols,
                                 index=next((i for i, col in enumerate(available_cols) 
                                          if any(word in col.lower() for word in ['–∞—Ä—Ç', 'art'])), 0))
            qty_col = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º:", available_cols,
                                 index=next((i for i, col in enumerate(available_cols) 
                                          if any(word in col.lower() for word in ['–∫–æ–ª', 'qty', '–∫–æ–ª–∏—á–µ—Å—Ç–≤'])), 0))
        
        with col2:
            st.write("**–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏:**")
            magazin_col = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Å –º–∞–≥–∞–∑–∏–Ω–æ–º:", available_cols,
                                     index=next((i for i, col in enumerate(available_cols) 
                                              if any(word in col.lower() for word in ['–º–∞–≥', 'magazin', '–º–∞–≥–∞–∑–∏–Ω'])), 0))
            name_col = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º:", available_cols,
                                  index=next((i for i, col in enumerate(available_cols) 
                                           if any(word in col.lower() for word in ['–Ω–∞–∑–≤', 'name', '–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω'])), 0))
            
            # –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–∫–∏ —Å —Å–µ–≥–º–µ–Ω—Ç–æ–º
            segment_col = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Å —Å–µ–≥–º–µ–Ω—Ç–æ–º (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):", 
                                     ['–ë–µ–∑ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏'] + available_cols)
        
        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏
        column_mapping = {
            date_col: 'Data',
            art_col: 'Art', 
            qty_col: 'Qty',
            magazin_col: 'Magazin',
            name_col: 'Name'
        }
        
        if segment_col != '–ë–µ–∑ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏':
            column_mapping[segment_col] = 'Segment'
        
        df = df.rename(columns=column_mapping)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        required_cols = ['Data', 'Art', 'Qty', 'Magazin', 'Name']
        missing_cols = [col for col in required_cols if col not in df.columns]
        
        if missing_cols:
            st.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")
        else:
            st.success("‚úÖ –í—Å–µ –∫–æ–ª–æ–Ω–∫–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω—ã")
            
            # –í—ã–±–æ—Ä —Å–µ–≥–º–µ–Ω—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            if 'Segment' in df.columns:
                st.subheader("üéØ –í—ã–±–æ—Ä —Å–µ–≥–º–µ–Ω—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
                unique_segments = sorted(df['Segment'].dropna().unique())
                
                col1, col2 = st.columns(2)
                with col1:
                    selected_segment = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Å–µ–≥–º–µ–Ω—Ç:", 
                                                  ['–í—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã'] + list(unique_segments))
                with col2:
                    if selected_segment != '–í—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã':
                        segment_count = len(df[df['Segment'] == selected_segment])
                        segment_arts = df[df['Segment'] == selected_segment]['Art'].nunique()
                        st.info(f"üìä –ó–∞–ø–∏—Å–µ–π: {segment_count}, –ê—Ä—Ç–∏–∫—É–ª–æ–≤: {segment_arts}")
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É —Å–µ–≥–º–µ–Ω—Ç—É
                if selected_segment != '–í—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã':
                    df = df[df['Segment'] == selected_segment].copy()
                    st.success(f"‚úÖ –í—ã–±—Ä–∞–Ω —Å–µ–≥–º–µ–Ω—Ç: {selected_segment}")
            
            data_loaded = True
            
            with st.expander("üìä –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö"):
                st.dataframe(df.head())
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π", len(df))
                with col2:
                    st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞—Ä—Ç–∏–∫—É–ª–æ–≤", df['Art'].nunique())
                with col3:
                    try:
                        date_range_min = pd.to_datetime(df['Data'], errors='coerce').min()
                        date_range_max = pd.to_datetime(df['Data'], errors='coerce').max()
                        if pd.notna(date_range_min) and pd.notna(date_range_max):
                            st.metric("–ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö", f"{date_range_min.strftime('%Y-%m-%d')} - {date_range_max.strftime('%Y-%m-%d')}")
                        else:
                            st.metric("–ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö", "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç")
                    except:
                        st.metric("–ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö", "–û—à–∏–±–∫–∞ –≤ –¥–∞—Ç–∞—Ö")
            
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {str(e)}")
        st.info("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –µ–≥–æ —Ñ–æ—Ä–º–∞—Ç")
        st.stop()
else:
    st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")

if data_loaded:
    st.header("üöÄ –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞")
    if st.button("‚ñ∂Ô∏è –ù–ê–ß–ê–¢–¨ –ê–ù–ê–õ–ò–ó", type="primary", use_container_width=True):
        st.session_state.run_analysis = True
    
    if not st.session_state.get('run_analysis', False):
        st.info("üëÜ –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞")
        st.stop()
else:
    st.stop()

# === –û–ë–†–ê–ë–û–¢–ö–ê ===
try:
    with st.spinner("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
        # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π
        df['Data'] = pd.to_datetime(df['Data'], dayfirst=True, errors='coerce')
        df = df.dropna(subset=['Data'])
        df = df[df['Qty'] >= 0]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
        if len(df) == 0:
            st.error("‚ùå –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏")
            st.stop()
        
        df['year_week'] = df['Data'].dt.strftime('%Y-%U')
        
        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –Ω–µ–¥–µ–ª—è–º —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–∞–º—è—Ç–∏
        weekly = df.groupby(['Art', 'year_week'])[['Qty']].sum().reset_index()
        unique_weeks = sorted(df['year_week'].unique())
        all_arts = df['Art'].unique()
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if len(all_arts) > 10000:
            st.warning("‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∞—Ä—Ç–∏–∫—É–ª–æ–≤. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ø-10000 –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º.")
            top_arts = df.groupby('Art')['Qty'].sum().nlargest(10000).index
            all_arts = top_arts
            df = df[df['Art'].isin(all_arts)]
            weekly = weekly[weekly['Art'].isin(all_arts)]
        
        all_weeks = pd.MultiIndex.from_product([all_arts, unique_weeks], names=['Art', 'year_week'])
        weekly = weekly.set_index(['Art', 'year_week']).reindex(all_weeks, fill_value=0).reset_index()
        
        # ABC-–∞–Ω–∞–ª–∏–∑ —Ç–æ–≤–∞—Ä–æ–≤
        abc_analysis = df.groupby('Art').agg({
            'Qty': ['sum', 'mean', 'count'],
            'Data': ['min', 'max']
        }).reset_index()
        
        abc_analysis.columns = ['Art', 'total_qty', 'avg_qty', 'sales_count', 'first_sale', 'last_sale']
        abc_analysis['days_in_catalog'] = (abc_analysis['last_sale'] - abc_analysis['first_sale']).dt.days + 1
        abc_analysis['sales_velocity'] = abc_analysis['total_qty'] / np.maximum(abc_analysis['days_in_catalog'], 1)
        
        abc_analysis = abc_analysis.sort_values('total_qty', ascending=False)
        abc_analysis['cum_qty'] = abc_analysis['total_qty'].cumsum()
        abc_analysis['cum_qty_pct'] = abc_analysis['cum_qty'] / abc_analysis['total_qty'].sum()
        
        def get_abc_category(cum_pct):
            if cum_pct <= 0.8:
                return 'A'
            elif cum_pct <= 0.95:
                return 'B'
            else:
                return 'C'
        
        abc_analysis['abc_category'] = abc_analysis['cum_qty_pct'].apply(get_abc_category)
        
        # –†–∞—Å—á–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã—Ö —Ñ–∏—á–µ–π
        def compute_enhanced_features(group):
            sorted_group = group.sort_values('year_week')
            qty_series = sorted_group['Qty']
            
            ma_3 = qty_series.rolling(3, min_periods=1).mean().iloc[-1] if len(qty_series) > 0 else 0
            ma_6 = qty_series.rolling(6, min_periods=1).mean().iloc[-1] if len(qty_series) > 0 else 0
            ma_12 = qty_series.rolling(12, min_periods=1).mean().iloc[-1] if len(qty_series) > 0 else 0
            
            consecutive_zeros = 0
            for val in reversed(qty_series.values):
                if val == 0:
                    consecutive_zeros += 1
                else:
                    break
            
            zero_weeks_12 = (qty_series.tail(12) == 0).sum()
            
            if len(qty_series) >= 4:
                try:
                    x = np.arange(len(qty_series))
                    trend = np.polyfit(x, qty_series, 1)[0]
                except:
                    trend = 0
            else:
                trend = 0
            
            volatility = qty_series.std() if len(qty_series) > 1 else 0
            
            return pd.DataFrame({
                'ma_3': [ma_3], 'ma_6': [ma_6], 'ma_12': [ma_12],
                'consecutive_zeros': [consecutive_zeros], 'zero_weeks_12': [zero_weeks_12],
                'trend': [trend], 'volatility': [volatility]
            })
        
        features = weekly.groupby('Art').apply(compute_enhanced_features, include_groups=False).reset_index()
        features = features.drop('level_1', axis=1, errors='ignore')
        
        # –î–æ–ª—è –º–∞–≥–∞–∑–∏–Ω–æ–≤ –±–µ–∑ –ø—Ä–æ–¥–∞–∂
        df['has_sales'] = df['Qty'] > 0
        store_sales = df.groupby(['Art', 'Magazin'])['has_sales'].max().reset_index()
        store_ratio = store_sales.groupby('Art')['has_sales'].mean().reset_index()
        store_ratio['no_store_ratio'] = 1 - store_ratio['has_sales']
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å ABC-–∞–Ω–∞–ª–∏–∑–æ–º
        features = features.merge(abc_analysis[['Art', 'total_qty', 'sales_velocity', 'abc_category', 'days_in_catalog']], on='Art', how='left')
        features = features.merge(store_ratio[['Art', 'no_store_ratio']], on='Art', how='left')
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –±–æ–ª–µ–µ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ª–µ–π–±–ª–æ–≤ –ø–æ —Å–µ–≥–º–µ–Ω—Ç—É
        def create_balanced_labels(row):
            score = 0
            
            if row['abc_category'] == 'C':
                if row['consecutive_zeros'] >= zero_weeks_threshold:
                    score += 3
                elif row['zero_weeks_12'] >= zero_weeks_threshold//2:
                    score += 2
                if row['no_store_ratio'] > max_store_ratio:
                    score += 2
                if row['total_qty'] < min_total_sales:
                    score += 2
                if row['trend'] < -0.1:
                    score += 1
            elif row['abc_category'] in ['A', 'B']:
                if row['consecutive_zeros'] >= zero_weeks_threshold * 1.5:
                    score += 2
                if row['no_store_ratio'] > 0.95:
                    score += 1
            
            return 1 if score >= 4 else 0
        
        features['label'] = features.apply(create_balanced_labels, axis=1)
        
        # –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π —á–µ—Ä–µ–∑ class_weight
        feature_cols = ['ma_3', 'ma_6', 'ma_12', 'consecutive_zeros', 'zero_weeks_12', 
                       'trend', 'volatility', 'no_store_ratio', 'total_qty', 'sales_velocity']
        
        X = features[feature_cols].fillna(0)
        y = features['label']
        
        st.write(f"**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:** –°–Ω—è—Ç—å: {y.sum()}, –û—Å—Ç–∞–≤–∏—Ç—å: {len(y) - y.sum()}")
        
        if len(y.unique()) > 1 and y.sum() > 0:
            X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42, test_size=0.3)
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ class_weight –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
            if use_balanced_model:
                clf = RandomForestClassifier(
                    n_estimators=50,  # –£–º–µ–Ω—å—à–∞–µ–º –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
                    random_state=42, 
                    class_weight='balanced',
                    max_depth=10,
                    min_samples_split=5, 
                    min_samples_leaf=2,
                    n_jobs=1  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤
                )
            else:
                clf = RandomForestClassifier(
                    n_estimators=50,
                    random_state=42,
                    max_depth=10,
                    min_samples_split=5, 
                    min_samples_leaf=2,
                    n_jobs=1
                )
            
            clf.fit(X_train, y_train)
            features['prob_dying'] = clf.predict_proba(X)[:, 1]
            train_score = clf.score(X_train, y_train)
            test_score = clf.score(X_test, y_test)
            
        else:
            st.warning("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
            features['prob_dying'] = features['label'].astype(float)
            train_score = test_score = 0.0

except Exception as e:
    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
    st.stop()

# === PROPHET –ü–†–û–ì–ù–û–ó–´ ===
forecast_df = pd.DataFrame()

if PROPHET_AVAILABLE:
    try:
        with st.spinner("üìà –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ Prophet..."):
            qty_by_art = features.sort_values('total_qty', ascending=False).head(min(TOP_N, 20))['Art']  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 20
            forecast_dfs = []
            
            progress_bar = st.progress(0)
            for i, art in enumerate(qty_by_art):
                try:
                    sales = df[df['Art'] == art].groupby('Data')[['Qty']].sum().reset_index()
                    if len(sales) < 8:
                        continue
                    
                    sales.columns = ['ds', 'y']
                    model = Prophet(
                        daily_seasonality=False, 
                        weekly_seasonality=False,  # –û—Ç–∫–ª—é—á–∞–µ–º –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ä–µ—Å—É—Ä—Å–æ–≤
                        yearly_seasonality=False,
                        changepoint_prior_scale=0.1,
                        interval_width=0.8
                    )
                    model.fit(sales)
                    future = model.make_future_dataframe(periods=30)
                    forecast = model.predict(future)
                    median_30 = forecast.tail(30)['yhat'].median()
                    forecast_dfs.append({'Art': art, 'forecast_30_median': max(0, median_30)})
                except:
                    continue
                
                progress_bar.progress((i + 1) / len(qty_by_art))
            
            forecast_df = pd.DataFrame(forecast_dfs)
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤: {str(e)}")
        forecast_df = pd.DataFrame()
else:
    st.info("‚ÑπÔ∏è Prophet –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–≥–Ω–æ–∑—ã –ø—Ä–æ–ø—É—â–µ–Ω—ã.")

# === –§–ò–ù–ê–õ–¨–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê ===
final = features.merge(forecast_df, on='Art', how='left') if not forecast_df.empty else features.copy()
if 'forecast_30_median' not in final.columns:
    final['forecast_30_median'] = np.nan

final = final.merge(df[['Art', 'Name']].drop_duplicates(), on='Art', how='left')

# –ü—Ä–∞–≤–∏–ª–∞ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
def get_detailed_reason(row):
    reasons = []
    if row['abc_category'] == 'C':
        reasons.append(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è C")
    if row['consecutive_zeros'] >= zero_weeks_threshold:
        reasons.append(f"–ë–µ–∑ –ø—Ä–æ–¥–∞–∂ {int(row['consecutive_zeros'])} –Ω–µ–¥–µ–ª—å")
    if row['zero_weeks_12'] >= zero_weeks_threshold//2:
        reasons.append(f"–ò–∑ 12 –Ω–µ–¥–µ–ª—å {int(row['zero_weeks_12'])} –±–µ–∑ –ø—Ä–æ–¥–∞–∂")
    if row['no_store_ratio'] > max_store_ratio:
        reasons.append(f"–í {(1-row['no_store_ratio'])*100:.0f}% –º–∞–≥–∞–∑–∏–Ω–æ–≤")
    if row['total_qty'] < min_total_sales:
        reasons.append(f"–ú–∞–ª—ã–π –æ–±—ä–µ–º ({row['total_qty']:.1f})")
    if pd.notnull(row.get('forecast_30_median')) and row['forecast_30_median'] < 0.5:
        reasons.append("–ü—Ä–æ–≥–Ω–æ–∑ –±–ª–∏–∑–æ–∫ –∫ –Ω—É–ª—é")
    if row['trend'] < -0.1:
        reasons.append("–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π —Ç—Ä–µ–Ω–¥")
    return "; ".join(reasons) if reasons else "–°—Ç–∞–±–∏–ª—å–Ω—ã–µ –ø—Ä–æ–¥–∞–∂–∏"

def get_final_recommendation(row):
    ml_score = row['prob_dying']
    if (row['abc_category'] == 'C' and row['consecutive_zeros'] >= zero_weeks_threshold and 
        row['total_qty'] < min_total_sales):
        return "üö´ –°–Ω—è—Ç—å"
    if ml_score > final_threshold:
        return "üö´ –°–Ω—è—Ç—å"
    elif ml_score > final_threshold * 0.7:
        return "‚ö†Ô∏è –ù–∞–±–ª—é–¥–∞—Ç—å"
    else:
        return "‚úÖ –û—Å—Ç–∞–≤–∏—Ç—å"

final['–ü—Ä–∏—á–∏–Ω–∞'] = final.apply(get_detailed_reason, axis=1)
final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è'] = final.apply(get_final_recommendation, axis=1)

# === –†–ï–ó–£–õ–¨–¢–ê–¢–´ ===
st.header("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")

col1, col2, col3, col4 = st.columns(4)
with col1:
    total_products = len(final)
    st.metric("–í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤", total_products)
with col2:
    candidates_remove = len(final[final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è'] == "üö´ –°–Ω—è—Ç—å"])
    st.metric("–ö —Å–Ω—è—Ç–∏—é", candidates_remove, f"{candidates_remove/total_products*100:.1f}%")
with col3:
    candidates_watch = len(final[final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è'] == "‚ö†Ô∏è –ù–∞–±–ª—é–¥–∞—Ç—å"])
    st.metric("–ù–∞–±–ª—é–¥–∞—Ç—å", candidates_watch, f"{candidates_watch/total_products*100:.1f}%")
with col4:
    if 'test_score' in locals() and test_score > 0:
        st.metric("–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏", f"{test_score:.2f}")

# ABC —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
st.subheader("üìà ABC –∞–Ω–∞–ª–∏–∑")
abc_dist = final['abc_category'].value_counts()
col1, col2, col3 = st.columns(3)
with col1:
    st.metric("–ö–∞—Ç–µ–≥–æ—Ä–∏—è A", abc_dist.get('A', 0))
with col2:
    st.metric("–ö–∞—Ç–µ–≥–æ—Ä–∏—è B", abc_dist.get('B', 0))
with col3:
    st.metric("–ö–∞—Ç–µ–≥–æ—Ä–∏—è C", abc_dist.get('C', 0))

# === –§–ò–õ–¨–¢–†–´ ===
st.subheader("üîç –§–∏–ª—å—Ç—Ä—ã")
col1, col2, col3 = st.columns(3)

with col1:
    filter_recommendation = st.selectbox("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:", 
                                       ["–í—Å–µ", "üö´ –°–Ω—è—Ç—å", "‚ö†Ô∏è –ù–∞–±–ª—é–¥–∞—Ç—å", "‚úÖ –û—Å—Ç–∞–≤–∏—Ç—å"])
    filter_abc = st.selectbox("ABC –∫–∞—Ç–µ–≥–æ—Ä–∏—è:", ["–í—Å–µ", "A", "B", "C"])

with col2:
    min_prob = st.slider("–ú–∏–Ω. –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–Ω—è—Ç–∏—è", 0.0, 1.0, 0.0, 0.1)
    min_zero_weeks = st.slider("–ú–∏–Ω. –Ω–µ–¥–µ–ª—å –±–µ–∑ –ø—Ä–æ–¥–∞–∂", 0, 20, 0)

with col3:
    search_art = st.text_input("–ü–æ–∏—Å–∫ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É/–Ω–∞–∑–≤–∞–Ω–∏—é")

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
filtered_df = final.copy()

if filter_recommendation != "–í—Å–µ":
    filtered_df = filtered_df[filtered_df['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è'] == filter_recommendation]

if filter_abc != "–í—Å–µ":
    filtered_df = filtered_df[filtered_df['abc_category'] == filter_abc]

filtered_df = filtered_df[
    (filtered_df['prob_dying'] >= min_prob) &
    (filtered_df['consecutive_zeros'] >= min_zero_weeks)
]

if search_art:
    mask = (filtered_df['Art'].astype(str).str.contains(search_art, case=False, na=False) |
            filtered_df['Name'].astype(str).str.contains(search_art, case=False, na=False))
    filtered_df = filtered_df[mask]

# === –¢–ê–ë–õ–ò–¶–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ===
st.subheader(f"üìã –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ({len(filtered_df)} —Ç–æ–≤–∞—Ä–æ–≤)")

display_columns = ['Art', 'Name', 'abc_category', 'total_qty', 'consecutive_zeros', 
                  'no_store_ratio', 'prob_dying', '–ü—Ä–∏—á–∏–Ω–∞', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è']

if 'forecast_30_median' in filtered_df.columns and not filtered_df['forecast_30_median'].isna().all():
    display_columns.insert(-2, 'forecast_30_median')

display_df = filtered_df[display_columns].copy()

display_df['no_store_ratio'] = display_df['no_store_ratio'].round(2)
if 'forecast_30_median' in display_df.columns:
    display_df['forecast_30_median'] = display_df['forecast_30_median'].round(1)
display_df['prob_dying'] = display_df['prob_dying'].round(3)
display_df['total_qty'] = display_df['total_qty'].round(1)

column_names = ['–ê—Ä—Ç–∏–∫—É–ª', '–ù–∞–∑–≤–∞–Ω–∏–µ', 'ABC', '–û–±—â–∏–π_–æ–±—ä–µ–º', '–ù–µ–¥–µ–ª—å_–±–µ–∑_–ø—Ä–æ–¥–∞–∂', 
               '–î–æ–ª—è_–º–∞–≥_–±–µ–∑_–ø—Ä–æ–¥–∞–∂']
if 'forecast_30_median' in display_df.columns:
    column_names.append('–ü—Ä–æ–≥–Ω–æ–∑_30–¥–Ω')
column_names.extend(['–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_—Å–Ω—è—Ç–∏—è', '–ü—Ä–∏—á–∏–Ω–∞', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è'])

display_df.columns = column_names

st.dataframe(display_df, use_container_width=True)

# === –≠–ö–°–ü–û–†–¢ ===
st.subheader("üíæ –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

if st.button("üì• –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ñ–∞–π–ª –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è"):
    try:
        output_columns = ['Art', 'Name', 'abc_category', 'total_qty', 'consecutive_zeros', 
                         'no_store_ratio', 'prob_dying', '–ü—Ä–∏—á–∏–Ω–∞', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è']
        
        if 'forecast_30_median' in final.columns:
            output_columns.insert(-2, 'forecast_30_median')
        
        output = final[output_columns].copy()
        
        from io import BytesIO
        buffer = BytesIO()
        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            output.to_excel(writer, sheet_name='–†–µ–∑—É–ª—å—Ç–∞—Ç—ã', index=False)
            
            stats = pd.DataFrame({
                '–ú–µ—Ç—Ä–∏–∫–∞': ['–í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤', '–ö —Å–Ω—è—Ç–∏—é', '–ù–∞–±–ª—é–¥–∞—Ç—å', '–û—Å—Ç–∞–≤–∏—Ç—å', '–ü–æ—Ä–æ–≥ ML'],
                '–ó–Ω–∞—á–µ–Ω–∏–µ': [total_products, candidates_remove, candidates_watch, 
                            total_products - candidates_remove - candidates_watch, final_threshold]
            })
            stats.to_excel(writer, sheet_name='–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', index=False)
            
            abc_summary = final.groupby(['abc_category', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è']).size().unstack(fill_value=0)
            abc_summary.to_excel(writer, sheet_name='ABC_–∞–Ω–∞–ª–∏–∑')
        
        st.download_button(
            label="üì• –°–∫–∞—á–∞—Ç—å Excel",
            data=buffer.getvalue(),
            file_name="product_analysis_results.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
        st.success("‚úÖ –§–∞–π–ª –≥–æ—Ç–æ–≤ –∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—é!")
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}")

# –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∏—Å—Ç–µ–º–µ
with st.expander("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ"):
    st.write("**–°—Ç–∞—Ç—É—Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤:**")
    st.write(f"- Prophet: {'‚úÖ –î–æ—Å—Ç—É–ø–µ–Ω' if PROPHET_AVAILABLE else '‚ùå –ù–µ–¥–æ—Å—Ç—É–ø–µ–Ω'}")
    st.write(f"- Sklearn: ‚úÖ –î–æ—Å—Ç—É–ø–µ–Ω")
    st.write(f"- Pandas: ‚úÖ –î–æ—Å—Ç—É–ø–µ–Ω")
    st.write(f"- –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∞—Ä—Ç–∏–∫—É–ª–æ–≤: {len(final) if 'final' in locals() else 0}")
    
    if not PROPHET_AVAILABLE:
        st.warning("‚ö†Ô∏è –î–ª—è –ø–æ–ª–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Prophet: pip install prophet")
