import streamlit as st
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

try:
    from prophet import Prophet
    PROPHET_AVAILABLE = True
except ImportError:
    PROPHET_AVAILABLE = False
    st.warning("‚ö†Ô∏è Prophet –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü—Ä–æ–≥–Ω–æ–∑—ã –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from io import BytesIO

st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ —Ç–æ–≤–∞—Ä–æ–≤", layout="wide")

if 'run_analysis' not in st.session_state:
    st.session_state.run_analysis = False

st.title("üîç –ê–Ω–∞–ª–∏–∑ —Ç–æ–≤–∞—Ä–æ–≤: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ —Å–Ω—è—Ç–∏–µ")

# === –ù–ê–°–¢–†–û–ô–ö–ò ===
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    TOP_N = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø-–∞—Ä—Ç–∏–∫—É–ª–æ–≤ –¥–ª—è Prophet", 10, 50, 20)
    
    st.subheader("üéØ –ö—Ä–∏—Ç–µ—Ä–∏–∏ —Å–Ω—è—Ç–∏—è")
    zero_weeks_threshold = st.slider("–ù–µ–¥–µ–ª—å –ø–æ–¥—Ä—è–¥ –±–µ–∑ –ø—Ä–æ–¥–∞–∂", 8, 20, 12)
    min_total_sales = st.slider("–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ–±—ä–µ–º –ø—Ä–æ–¥–∞–∂", 1, 50, 5)
    max_store_ratio = st.slider("–ú–∞–∫—Å. –¥–æ–ª—è –º–∞–≥–∞–∑–∏–Ω–æ–≤ –±–µ–∑ –ø—Ä–æ–¥–∞–∂ (%)", 70, 95, 85, 5) / 100
    
    st.subheader("ü§ñ –ú–æ–¥–µ–ª—å ML")
    use_balanced_model = st.checkbox("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫—É –∫–ª–∞—Å—Å–æ–≤", value=True)
    final_threshold = st.slider("–§–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è —Å–Ω—è—Ç–∏—è (%)", 50, 90, 70, 5) / 100

# === –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ===
st.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
st.info("üí° –§–æ—Ä–º–∞—Ç: –¥–∞—Ç–∞, –∞—Ä—Ç–∏–∫—É–ª, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, –º–∞–≥–∞–∑–∏–Ω, –Ω–∞–∑–≤–∞–Ω–∏–µ")

uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ Excel —Ñ–∞–π–ª", type=['xlsx', 'xls'])

def load_and_process_data(uploaded_file):
    if uploaded_file is None:
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")
        return None, False
    
    try:
        file_size = len(uploaded_file.read())
        uploaded_file.seek(0)
        
        if file_size > 50 * 1024 * 1024:
            st.error("‚ùå –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º—É–º: 50MB")
            return None, False
        
        excel_file = pd.ExcelFile(uploaded_file)
        selected_sheet = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –ª–∏—Å—Ç:", excel_file.sheet_names) if len(excel_file.sheet_names) > 1 else excel_file.sheet_names[0]
        
        df = pd.read_excel(uploaded_file, sheet_name=selected_sheet, nrows=100000)
        if len(df) == 100000:
            st.warning("‚ö†Ô∏è –§–∞–π–ª –æ–±—Ä–µ–∑–∞–Ω –¥–æ 100,000 —Å—Ç—Ä–æ–∫")
        
        st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫")
        
        # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
        available_cols = list(df.columns)
        col1, col2 = st.columns(2)
        
        with col1:
            date_col = st.selectbox("–î–∞—Ç–∞:", available_cols, index=next((i for i, col in enumerate(available_cols) if any(word in col.lower() for word in ['–¥–∞—Ç', 'date'])), 0))
            art_col = st.selectbox("–ê—Ä—Ç–∏–∫—É–ª:", available_cols, index=next((i for i, col in enumerate(available_cols) if any(word in col.lower() for word in ['–∞—Ä—Ç', 'art'])), 0))
            qty_col = st.selectbox("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ:", available_cols, index=next((i for i, col in enumerate(available_cols) if any(word in col.lower() for word in ['–∫–æ–ª', 'qty', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ'])), 0))
        
        with col2:
            magazin_col = st.selectbox("–ú–∞–≥–∞–∑–∏–Ω:", available_cols, index=next((i for i, col in enumerate(available_cols) if any(word in col.lower() for word in ['–º–∞–≥', 'magazin', '–º–∞–≥–∞–∑–∏–Ω'])), 0))
            name_col = st.selectbox("–ù–∞–∑–≤–∞–Ω–∏–µ:", available_cols, index=next((i for i, col in enumerate(available_cols) if any(word in col.lower() for word in ['–Ω–∞–∑–≤', 'name', '–Ω–∞–∑–≤–∞–Ω–∏–µ'])), 0))
            segment_col = st.selectbox("–°–µ–≥–º–µ–Ω—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):", ['–ë–µ–∑ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏'] + available_cols)
        
        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
        column_mapping = {date_col: 'Data', art_col: 'Art', qty_col: 'Qty', magazin_col: 'Magazin', name_col: 'Name'}
        if segment_col != '–ë–µ–∑ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏':
            column_mapping[segment_col] = 'Segment'
        
        df = df.rename(columns=column_mapping)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_cols = ['Data', 'Art', 'Qty', 'Magazin', 'Name']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            st.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")
            return None, False
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Å–µ–≥–º–µ–Ω—Ç—É
        if 'Segment' in df.columns:
            st.subheader("üéØ –í—ã–±–æ—Ä —Å–µ–≥–º–µ–Ω—Ç–∞")
            unique_segments = sorted(df['Segment'].dropna().unique())
            selected_segment = st.selectbox("–°–µ–≥–º–µ–Ω—Ç:", ['–í—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã'] + list(unique_segments))
            
            if selected_segment != '–í—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã':
                df = df[df['Segment'] == selected_segment].copy()
                st.success(f"‚úÖ –í—ã–±—Ä–∞–Ω —Å–µ–≥–º–µ–Ω—Ç: {selected_segment}")
        
        with st.expander("üìä –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä"):
            st.dataframe(df.head())
            col1, col2, col3 = st.columns(3)
            with col1: st.metric("–ó–∞–ø–∏—Å–µ–π", len(df))
            with col2: st.metric("–ê—Ä—Ç–∏–∫—É–ª–æ–≤", df['Art'].nunique())
            with col3:
                try:
                    date_min = pd.to_datetime(df['Data'], errors='coerce').min()
                    date_max = pd.to_datetime(df['Data'], errors='coerce').max()
                    st.metric("–ü–µ—Ä–∏–æ–¥", f"{date_min.strftime('%Y-%m-%d')} - {date_max.strftime('%Y-%m-%d')}")
                except:
                    st.metric("–ü–µ—Ä–∏–æ–¥", "–û—à–∏–±–∫–∞ –¥–∞—Ç")
        
        return df, True
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}")
        return None, False

df, data_loaded = load_and_process_data(uploaded_file)

if data_loaded:
    st.header("üöÄ –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞")
    if st.button("‚ñ∂Ô∏è –ù–ê–ß–ê–¢–¨ –ê–ù–ê–õ–ò–ó", type="primary", use_container_width=True):
        st.session_state.run_analysis = True
    
    if not st.session_state.get('run_analysis', False):
        st.info("üëÜ –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞")
        st.stop()
else:
    st.stop()

# === –û–°–ù–û–í–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê ===
def process_data(df):
    with st.spinner("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
        # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        df['Data'] = pd.to_datetime(df['Data'], dayfirst=True, errors='coerce')
        df = df.dropna(subset=['Data'])
        df['Qty'] = pd.to_numeric(df['Qty'], errors='coerce').fillna(0)
        df = df[df['Qty'] >= 0]
        
        if len(df) == 0:
            st.error("‚ùå –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
            st.stop()
        
        df['year_week'] = df['Data'].dt.strftime('%Y-%U')
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∞—Ä—Ç–∏–∫—É–ª–æ–≤
        all_arts = df['Art'].unique()
        if len(all_arts) > 5000:
            st.warning("‚ö†Ô∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ø-5000 –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º")
            top_arts = df.groupby('Art')['Qty'].sum().nlargest(5000).index
            all_arts = top_arts
            df = df[df['Art'].isin(all_arts)]
        
        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –Ω–µ–¥–µ–ª—è–º
        weekly = df.groupby(['Art', 'year_week'])['Qty'].sum().reset_index()
        unique_weeks = sorted(df['year_week'].unique())
        all_weeks = pd.MultiIndex.from_product([all_arts, unique_weeks], names=['Art', 'year_week'])
        weekly = weekly.set_index(['Art', 'year_week']).reindex(all_weeks, fill_value=0).reset_index()
        
        return df, weekly, all_arts, unique_weeks

def calculate_abc_xyz_analysis(df):
    # ABC –∞–Ω–∞–ª–∏–∑
    abc_analysis = df.groupby('Art').agg({
        'Qty': ['sum', 'mean', 'std'],
        'Data': ['min', 'max']
    }).reset_index()
    
    abc_analysis.columns = ['Art', 'total_qty', 'avg_qty', 'std_qty', 'first_sale', 'last_sale']
    abc_analysis['days_in_catalog'] = (abc_analysis['last_sale'] - abc_analysis['first_sale']).dt.days + 1
    
    # ABC –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–µ—Ä–µ–¥ –∫—É–º—É–ª—è—Ç–∏–≤–Ω—ã–º —Ä–∞—Å—á–µ—Ç–æ–º)
    abc_analysis = abc_analysis.sort_values('total_qty', ascending=False).reset_index(drop=True)
    abc_analysis['cum_qty'] = abc_analysis['total_qty'].cumsum()
    total_sum = abc_analysis['total_qty'].sum()
    abc_analysis['cum_qty_pct'] = abc_analysis['cum_qty'] / total_sum if total_sum > 0 else 0
    
    def get_abc_category(cum_pct):
        if cum_pct <= 0.8: return 'A'
        elif cum_pct <= 0.95: return 'B'
        else: return 'C'
    
    abc_analysis['abc_category'] = abc_analysis['cum_qty_pct'].apply(get_abc_category)
    
    # XYZ –∞–Ω–∞–ª–∏–∑ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π)
    abc_analysis['coefficient_variation'] = np.where(
        abc_analysis['avg_qty'] > 0,
        abc_analysis['std_qty'] / abc_analysis['avg_qty'],
        999  # –ë–æ–ª—å—à–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —Ç–æ–≤–∞—Ä–æ–≤ –±–µ–∑ –ø—Ä–æ–¥–∞–∂
    )
    
    def get_xyz_category(cv):
        if cv <= 0.1: return 'X'  # –°—Ç–∞–±–∏–ª—å–Ω—ã–π —Å–ø—Ä–æ—Å
        elif cv <= 0.25: return 'Y'  # –£–º–µ—Ä–µ–Ω–Ω–æ –∏–∑–º–µ–Ω—á–∏–≤—ã–π
        else: return 'Z'  # –ù–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–π —Å–ø—Ä–æ—Å
    
    abc_analysis['xyz_category'] = abc_analysis['coefficient_variation'].apply(get_xyz_category)
    
    return abc_analysis

def calculate_features(weekly, df):
    def compute_features(group):
        sorted_group = group.sort_values('year_week')
        qty_series = sorted_group['Qty'].values
        
        if len(qty_series) == 0:
            return pd.Series({
                'ma_3': 0, 
                'ma_6': 0, 
                'consecutive_zeros': 0,
                'zero_weeks_12': 0, 
                'trend': 0
            })
        
        # –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ
        qty_series_pd = pd.Series(qty_series)
        ma_3 = qty_series_pd.rolling(3, min_periods=1).mean().iloc[-1]
        ma_6 = qty_series_pd.rolling(6, min_periods=1).mean().iloc[-1]
        
        # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –Ω—É–ª–∏ —Å –∫–æ–Ω—Ü–∞
        consecutive_zeros = 0
        for val in reversed(qty_series):
            if val == 0: 
                consecutive_zeros += 1
            else: 
                break
        
        # –ù—É–ª–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 12 –Ω–µ–¥–µ–ª—å
        zero_weeks_12 = int(np.sum(qty_series[-12:] == 0)) if len(qty_series) >= 12 else int(np.sum(qty_series == 0))
        
        # –¢—Ä–µ–Ω–¥
        trend = 0
        if len(qty_series) >= 4:
            try:
                x = np.arange(len(qty_series))
                coeffs = np.polyfit(x, qty_series, 1)
                trend = float(coeffs[0])
            except:
                trend = 0
        
        return pd.Series({
            'ma_3': float(ma_3), 
            'ma_6': float(ma_6), 
            'consecutive_zeros': int(consecutive_zeros),
            'zero_weeks_12': int(zero_weeks_12), 
            'trend': float(trend)
        })
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∏ –ø–æ–ª—É—á–∞–µ–º DataFrame —Å Art –≤ –∏–Ω–¥–µ–∫—Å–µ
    features = weekly.groupby('Art').apply(compute_features, include_groups=False).reset_index()
    
    # –†–∞—Å—á–µ—Ç –¥–æ–ª–∏ –º–∞–≥–∞–∑–∏–Ω–æ–≤ –±–µ–∑ –ø—Ä–æ–¥–∞–∂
    total_stores = df['Magazin'].nunique()
    
    if total_stores == 0:
        st.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –º–∞–≥–∞–∑–∏–Ω–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö")
        st.stop()
    
    # –ú–∞–≥–∞–∑–∏–Ω—ã —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—Ä—Ç–∏–∫—É–ª–∞
    stores_with_sales = df[df['Qty'] > 0].groupby('Art')['Magazin'].nunique().reset_index()
    stores_with_sales.columns = ['Art', 'stores_with_sales']
    stores_with_sales['no_store_ratio'] = 1 - (stores_with_sales['stores_with_sales'] / total_stores)
    
    features = features.merge(stores_with_sales[['Art', 'no_store_ratio']], on='Art', how='left')
    features['no_store_ratio'] = features['no_store_ratio'].fillna(1.0)
    
    return features

def create_ml_model(features, abc_analysis):
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–æ–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê)
    def create_labels(row):
        score = 0
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏—è C - –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏
        if row['abc_category'] == 'C':
            if row['consecutive_zeros'] >= zero_weeks_threshold: 
                score += 3
            elif row['zero_weeks_12'] >= zero_weeks_threshold // 2: 
                score += 2
            
            if row['no_store_ratio'] > max_store_ratio: 
                score += 2
            
            if row['total_qty'] < min_total_sales: 
                score += 2
            
            if row['trend'] < -0.1: 
                score += 1
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏—è B - —É–º–µ—Ä–µ–Ω–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ (–ò–°–ü–†–ê–í–õ–ï–ù–û)
        elif row['abc_category'] == 'B':
            if row['consecutive_zeros'] >= zero_weeks_threshold * 2:  # 24 –Ω–µ–¥–µ–ª–∏
                score += 3
            elif row['consecutive_zeros'] >= zero_weeks_threshold:  # 12 –Ω–µ–¥–µ–ª—å
                score += 2
            
            if row['no_store_ratio'] > max_store_ratio:  # 85%
                score += 2
            
            if row['total_qty'] < min_total_sales * 2:  # 10 –µ–¥–∏–Ω–∏—Ü
                score += 1
            
            if row['trend'] < -0.1:
                score += 1
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏—è A - —Ç–æ–ª—å–∫–æ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏
        elif row['abc_category'] == 'A':
            if row['consecutive_zeros'] >= zero_weeks_threshold * 3:  # 36 –Ω–µ–¥–µ–ª—å
                score += 2
            if row['no_store_ratio'] > 0.95:  # 95%
                score += 1
        
        # –ö—Ä–∏—Ç–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏ –¥–ª—è –õ–Æ–ë–û–ô –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        if row['consecutive_zeros'] >= zero_weeks_threshold * 2 and row['no_store_ratio'] > max_store_ratio:
            score += 2  # –£—Å–∏–ª–µ–Ω–∏–µ –¥–ª—è –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Ñ–∞–∫—Ç–æ—Ä–æ–≤
        
        return 1 if score >= 4 else 0
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    final_features = features.merge(
        abc_analysis[['Art', 'total_qty', 'abc_category', 'last_sale']], 
        on='Art', 
        how='left'
    )
    final_features['label'] = final_features.apply(create_labels, axis=1)
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    feature_cols = ['ma_3', 'ma_6', 'consecutive_zeros', 'zero_weeks_12', 'trend', 'no_store_ratio', 'total_qty']
    X = final_features[feature_cols].fillna(0)
    y = final_features['label']
    
    st.write(f"**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:** –°–Ω—è—Ç—å: {y.sum()}, –û—Å—Ç–∞–≤–∏—Ç—å: {len(y) - y.sum()}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è
    if len(y.unique()) > 1 and y.sum() >= 2:
        try:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, 
                stratify=y, 
                random_state=42, 
                test_size=0.3
            )
            
            clf = RandomForestClassifier(
                n_estimators=30, 
                random_state=42, 
                class_weight='balanced' if use_balanced_model else None,
                max_depth=8, 
                min_samples_split=5, 
                n_jobs=1
            )
            
            clf.fit(X_train, y_train)
            final_features['prob_dying'] = clf.predict_proba(X)[:, 1] * 100
            test_score = clf.score(X_test, y_test)
            
        except Exception as e:
            st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ ML: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –ª–æ–≥–∏–∫—É.")
            final_features['prob_dying'] = final_features['label'].astype(float) * 100
            test_score = 0.0
    else:
        st.warning("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML. –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –ª–æ–≥–∏–∫—É.")
        final_features['prob_dying'] = final_features['label'].astype(float) * 100
        test_score = 0.0
    
    return final_features, test_score

def create_prophet_forecasts(df, abc_analysis):
    if not PROPHET_AVAILABLE:
        return pd.DataFrame()
    
    try:
        with st.spinner("üìà –ü—Ä–æ–≥–Ω–æ–∑—ã Prophet..."):
            top_arts = abc_analysis.nlargest(TOP_N, 'total_qty')['Art']
            forecasts = []
            
            for art in top_arts:
                try:
                    sales = df[df['Art'] == art].groupby('Data')['Qty'].sum().reset_index()
                    if len(sales) < 8: 
                        continue
                    
                    sales.columns = ['ds', 'y']
                    
                    model = Prophet(
                        daily_seasonality=False, 
                        weekly_seasonality=False, 
                        yearly_seasonality=False,
                        changepoint_prior_scale=0.05
                    )
                    
                    with warnings.catch_warnings():
                        warnings.simplefilter("ignore")
                        model.fit(sales)
                        future = model.make_future_dataframe(periods=30)
                        forecast = model.predict(future)
                    
                    median_30 = max(0, forecast.tail(30)['yhat'].median())
                    forecasts.append({'Art': art, 'forecast_30_median': float(median_30)})
                    
                except Exception as e:
                    continue
            
            return pd.DataFrame(forecasts)
            
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Prophet: {e}")
        return pd.DataFrame()

def get_recommendations(row):
    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏—á–∏–Ω
    reasons = []
    
    if row['abc_category'] == 'C': 
        reasons.append("–ö–∞—Ç–µ–≥–æ—Ä–∏—è C")
    elif row['abc_category'] == 'B':
        reasons.append("–ö–∞—Ç–µ–≥–æ—Ä–∏—è B")
    
    if row['consecutive_zeros'] >= zero_weeks_threshold * 2:
        reasons.append(f"–ë–µ–∑ –ø—Ä–æ–¥–∞–∂ {int(row['consecutive_zeros'])} –Ω–µ–¥–µ–ª—å (–∫—Ä–∏—Ç–∏—á–Ω–æ!)")
    elif row['consecutive_zeros'] >= zero_weeks_threshold: 
        reasons.append(f"–ë–µ–∑ –ø—Ä–æ–¥–∞–∂ {int(row['consecutive_zeros'])} –Ω–µ–¥–µ–ª—å")
    
    if row['zero_weeks_12'] >= zero_weeks_threshold // 2: 
        reasons.append(f"–ò–∑ 12 –Ω–µ–¥–µ–ª—å {int(row['zero_weeks_12'])} –±–µ–∑ –ø—Ä–æ–¥–∞–∂")
    
    if row['no_store_ratio'] > max_store_ratio: 
        stores_with_sales_pct = (1 - row['no_store_ratio']) * 100
        reasons.append(f"–ü—Ä–æ–¥–∞–∂–∏ –≤ {stores_with_sales_pct:.0f}% –º–∞–≥–∞–∑–∏–Ω–æ–≤")
    
    if row['total_qty'] < min_total_sales: 
        reasons.append(f"–ú–∞–ª—ã–π –æ–±—ä–µ–º ({row['total_qty']:.1f})")
    elif row['total_qty'] < min_total_sales * 2:
        reasons.append(f"–ù–∏–∑–∫–∏–π –æ–±—ä–µ–º ({row['total_qty']:.1f})")
    
    if row['trend'] < -0.1: 
        reasons.append("–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π —Ç—Ä–µ–Ω–¥")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø—Ä–æ–¥–∞–∂–∏
    if pd.notnull(row.get('last_sale')):
        last_sale_str = row['last_sale'].strftime('%Y-%m-%d')
        reasons.append(f"–ü–æ—Å–ª–µ–¥–Ω—è—è –ø—Ä–æ–¥–∞–∂–∞: {last_sale_str}")
    
    reason = "; ".join(reasons) if reasons else "–°—Ç–∞–±–∏–ª—å–Ω—ã–µ –ø—Ä–æ–¥–∞–∂–∏"
    
    # –ö–†–ò–¢–ò–ß–ù–´–ï –°–õ–£–ß–ê–ò - –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç ML
    # 1. –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –¥–æ–ª–≥–æ–µ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ–¥–∞–∂
    if row['consecutive_zeros'] >= zero_weeks_threshold * 3:  # 36 –Ω–µ–¥–µ–ª—å
        return reason, "üö´ –°–Ω—è—Ç—å"
    
    # 2. –ö–∞—Ç–µ–≥–æ—Ä–∏—è C —Å –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ–º –≤—Å–µ—Ö –ø–æ—Ä–æ–≥–æ–≤
    if (row['abc_category'] == 'C' and 
        row['consecutive_zeros'] >= zero_weeks_threshold and 
        row['total_qty'] < min_total_sales and
        row['no_store_ratio'] > max_store_ratio):
        return reason, "üö´ –°–Ω—è—Ç—å"
    
    # 3. –ö–∞—Ç–µ–≥–æ—Ä–∏—è B —Å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º–∏
    if (row['abc_category'] == 'B' and 
        row['consecutive_zeros'] >= zero_weeks_threshold * 2 and 
        row['no_store_ratio'] > max_store_ratio):
        return reason, "üö´ –°–Ω—è—Ç—å"
    
    # 4. –î–æ–ª–≥–æ–µ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ + –Ω–∏–∑–∫–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –¥–ª—è B
    if (row['abc_category'] == 'B' and
        row['consecutive_zeros'] >= zero_weeks_threshold * 1.5 and
        row['no_store_ratio'] > 0.85 and
        row['total_qty'] < min_total_sales * 2):
        return reason, "‚ö†Ô∏è –ù–∞–±–ª—é–¥–∞—Ç—å"
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –ª–æ–≥–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ ML
    prob_threshold_pct = final_threshold * 100
    
    if row['prob_dying'] > prob_threshold_pct:
        return reason, "üö´ –°–Ω—è—Ç—å"
    elif row['prob_dying'] > prob_threshold_pct * 0.7:
        return reason, "‚ö†Ô∏è –ù–∞–±–ª—é–¥–∞—Ç—å"
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è "–ù–∞–±–ª—é–¥–∞—Ç—å"
    if (row['consecutive_zeros'] >= zero_weeks_threshold and 
        row['no_store_ratio'] > 0.75):
        return reason, "‚ö†Ô∏è –ù–∞–±–ª—é–¥–∞—Ç—å"
    
    return reason, "‚úÖ –û—Å—Ç–∞–≤–∏—Ç—å"

# –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞
df, weekly, all_arts, unique_weeks = process_data(df)
abc_analysis = calculate_abc_xyz_analysis(df)
features = calculate_features(weekly, df)
final_features, test_score = create_ml_model(features, abc_analysis)
forecast_df = create_prophet_forecasts(df, abc_analysis)

# –§–∏–Ω–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
final = final_features.merge(abc_analysis[['Art', 'xyz_category', 'last_sale']], on='Art', how='left')
if not forecast_df.empty:
    final = final.merge(forecast_df, on='Art', how='left')
final = final.merge(df[['Art', 'Name']].drop_duplicates(), on='Art', how='left')

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
recommendations = final.apply(get_recommendations, axis=1)
final['–ü—Ä–∏—á–∏–Ω–∞'] = [rec[0] for rec in recommendations]
final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è'] = [rec[1] for rec in recommendations]

# === –†–ï–ó–£–õ–¨–¢–ê–¢–´ ===
st.header("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")

total_products = len(final)
candidates_remove = len(final[final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è'] == "üö´ –°–Ω—è—Ç—å"])
candidates_watch = len(final[final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è'] == "‚ö†Ô∏è –ù–∞–±–ª—é–¥–∞—Ç—å"])

col1, col2, col3, col4 = st.columns(4)
with col1: st.metric("–í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤", total_products)
with col2: st.metric("–ö —Å–Ω—è—Ç–∏—é", candidates_remove, f"{candidates_remove/total_products*100:.1f}%")
with col3: st.metric("–ù–∞–±–ª—é–¥–∞—Ç—å", candidates_watch, f"{candidates_watch/total_products*100:.1f}%")
with col4: st.metric("–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏", f"{test_score:.2f}" if test_score > 0 else "N/A")

# ABC/XYZ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
st.subheader("üìà ABC/XYZ –∞–Ω–∞–ª–∏–∑")
abc_dist = final['abc_category'].value_counts()
xyz_dist = final['xyz_category'].value_counts()

col1, col2 = st.columns(2)
with col1:
    st.write("**ABC –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:**")
    st.write(f"A: {abc_dist.get('A', 0)}, B: {abc_dist.get('B', 0)}, C: {abc_dist.get('C', 0)}")
with col2:
    st.write("**XYZ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:**")
    st.write(f"X: {xyz_dist.get('X', 0)}, Y: {xyz_dist.get('Y', 0)}, Z: {xyz_dist.get('Z', 0)}")

# === –§–ò–õ–¨–¢–†–´ –ò –¢–ê–ë–õ–ò–¶–ê ===
st.subheader("üîç –§–∏–ª—å—Ç—Ä—ã")
col1, col2, col3 = st.columns(3)

with col1:
    filter_recommendation = st.selectbox("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:", ["–í—Å–µ", "üö´ –°–Ω—è—Ç—å", "‚ö†Ô∏è –ù–∞–±–ª—é–¥–∞—Ç—å", "‚úÖ –û—Å—Ç–∞–≤–∏—Ç—å"])
    filter_abc = st.selectbox("ABC:", ["–í—Å–µ", "A", "B", "C"])
with col2:
    min_prob = st.slider("–ú–∏–Ω. –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å (%)", 0, 100, 0)
    filter_xyz = st.selectbox("XYZ:", ["–í—Å–µ", "X", "Y", "Z"])
with col3:
    min_zero_weeks = st.slider("–ú–∏–Ω. –Ω–µ–¥–µ–ª—å –±–µ–∑ –ø—Ä–æ–¥–∞–∂", 0, 20, 0)
    search_art = st.text_input("–ü–æ–∏—Å–∫ –∞—Ä—Ç–∏–∫—É–ª–∞/–Ω–∞–∑–≤–∞–Ω–∏—è")

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
filtered_df = final.copy()
if filter_recommendation != "–í—Å–µ":
    filtered_df = filtered_df[filtered_df['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è'] == filter_recommendation]
if filter_abc != "–í—Å–µ":
    filtered_df = filtered_df[filtered_df['abc_category'] == filter_abc]
if filter_xyz != "–í—Å–µ":
    filtered_df = filtered_df[filtered_df['xyz_category'] == filter_xyz]

filtered_df = filtered_df[
    (filtered_df['prob_dying'] >= min_prob) &
    (filtered_df['consecutive_zeros'] >= min_zero_weeks)
]

if search_art:
    mask = (filtered_df['Art'].astype(str).str.contains(search_art, case=False, na=False) |
            filtered_df['Name'].astype(str).str.contains(search_art, case=False, na=False))
    filtered_df = filtered_df[mask]

# –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
st.subheader(f"üìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã ({len(filtered_df)} —Ç–æ–≤–∞—Ä–æ–≤)")

display_columns = ['Art', 'Name', 'abc_category', 'xyz_category', 'total_qty', 'consecutive_zeros', 'no_store_ratio', 'prob_dying', '–ü—Ä–∏—á–∏–Ω–∞', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è']
if 'forecast_30_median' in filtered_df.columns:
    display_columns.insert(-2, 'forecast_30_median')

display_df = filtered_df[display_columns].copy()
display_df['no_store_ratio'] = (display_df['no_store_ratio'] * 100).round(1)
display_df['prob_dying'] = display_df['prob_dying'].round(1)

column_names = ['–ê—Ä—Ç–∏–∫—É–ª', '–ù–∞–∑–≤–∞–Ω–∏–µ', 'ABC', 'XYZ', '–û–±—ä–µ–º', '–ù–µ–¥–µ–ª—å_–±–µ–∑_–ø—Ä–æ–¥–∞–∂', '–ú–∞–≥–∞–∑–∏–Ω—ã_–±–µ–∑_–ø—Ä–æ–¥–∞–∂_%', '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_—Å–Ω—è—Ç–∏—è_%']
if 'forecast_30_median' in display_df.columns:
    column_names.append('–ü—Ä–æ–≥–Ω–æ–∑_30–¥–Ω')
column_names.extend(['–ü—Ä–∏—á–∏–Ω–∞', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è'])

display_df.columns = column_names
st.dataframe(display_df, use_container_width=True)

# === –≠–ö–°–ü–û–†–¢ ===
st.subheader("üíæ –≠–∫—Å–ø–æ—Ä—Ç")
if st.button("üì• –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å Excel"):
    try:
        buffer = BytesIO()
        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            output_cols = ['Art', 'Name', 'abc_category', 'xyz_category', 'total_qty', 'consecutive_zeros', 'no_store_ratio', 'prob_dying', '–ü—Ä–∏—á–∏–Ω–∞', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è']
            if 'forecast_30_median' in final.columns:
                output_cols.insert(-2, 'forecast_30_median')
            
            final[output_cols].to_excel(writer, sheet_name='–†–µ–∑—É–ª—å—Ç–∞—Ç—ã', index=False)
            
            stats = pd.DataFrame({
                '–ú–µ—Ç—Ä–∏–∫–∞': ['–í—Å–µ–≥–æ', '–°–Ω—è—Ç—å', '–ù–∞–±–ª—é–¥–∞—Ç—å', '–û—Å—Ç–∞–≤–∏—Ç—å', '–ü–æ—Ä–æ–≥_ML_%'],
                '–ó–Ω–∞—á–µ–Ω–∏–µ': [total_products, candidates_remove, candidates_watch, 
                           total_products - candidates_remove - candidates_watch, final_threshold*100]
            })
            stats.to_excel(writer, sheet_name='–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', index=False)
        
        st.download_button("üì• –°–∫–∞—á–∞—Ç—å Excel", buffer.getvalue(), "analysis_results.xlsx", 
                          "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        st.success("‚úÖ –ì–æ—Ç–æ–≤–æ!")
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")

with st.expander("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"):
    st.write(f"**–°—Ç–∞—Ç—É—Å:** Prophet {'‚úÖ' if PROPHET_AVAILABLE else '‚ùå'}, –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(final)}")
    if not PROPHET_AVAILABLE:
        st.warning("‚ö†Ô∏è –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Prophet: pip install prophet")
